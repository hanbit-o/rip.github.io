<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners -->
  <meta name="description" content="SuctionPrompt: Visual-assisted Robotic Picking with a Suction Cup Using Vision-Language Models and Facile Hardware Design">
  <meta property="og:title" content="SuctionPrompt完: Visual-assisted Robotic Picking with Vision-Language Models"/>
  <meta property="og:description" content="A versatile robotic system that utilizes VLMs with 3D detections for product-picking tasks in diverse environments"/>
  <meta property="og:url" content="https://tomohiromotoda.github.io/research/suction.prompt.html"/>
  <meta property="og:image" content="static/img/overview.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="SuctionPrompt完: Visual-assisted Robotic Picking">
  <meta name="twitter:description" content="A versatile robotic system that utilizes VLMs with 3D detections for product-picking tasks">
  <meta name="twitter:image" content="static/img/overview.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="robotics, vision-language models, robotic manipulation, suction cup, VLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>SuctionPrompt完</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">SuctionPrompt完: Visual-assisted Robotic Picking with a Suction Cup Using Vision-Language Models and Facile Hardware Design</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://tomohiromotoda.github.io/" target="_blank">Tomohiro Motoda</a><sup>*</sup>,</span>
                <span class="author-block">
                  Takahide Kitamura<sup>*</sup>,</span>
                  <span class="author-block">
                  Ryo Hanai,
                  </span>
                  <span class="author-block">
                  Yukiyasu Domae
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">National Institute of Advanced Industrial Science and Technology (AIST)<br>Journal of Robotics and Mechatronics (Accepted), 2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="static/pdf/SuctionPrompt.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.23640" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/video/teaser_suction_prompt.mp4#t=2.4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Our study introduces <strong>SuctionPrompt完</strong>, a robotic manipulation system equipped with a suction-cup-based gripper and guided by Vision-Language Models (VLMs). 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The development of large language models and vision-language models (VLMs) has resulted in the increasing use of robotic systems in various fields. 
        However, the effective integration of these models into real-world robotic tasks is a key challenge. 
        We developed a versatile robotic system called <strong>SuctionPrompt完</strong> that utilizes prompting techniques of VLMs combined with 3D detections to perform product-picking tasks in diverse and dynamic environments. 
        Our method highlights the importance of integrating 3D spatial information with adaptive action planning to enable robots to approach and manipulate objects in novel environments. 
        In the validation experiments, the system accurately selected suction points 75.4%, and achieved a 65.0% success rate in picking common items. 
        This study highlights the effectiveness of VLMs in robotic manipulation tasks, even with simple 3D processing. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- overview block -->
<section class="section hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">System Overview</h2>
      <div class="has-text-centered">
        <img src="./static/img/overview.png" alt="System Overview" title="System Overview" width="100%" style="max-width: 900px;">
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">Methodology</h2>
      <div class="has-text-centered">
        <img src="./static/img/flow-suctionprompt.png" alt="Flowchart" title="Methodology Flowchart" width="80%" style="max-width: 700px;">
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">Visual Results</h2>
      <div class="has-text-centered">
        <img src="./static/img/vision.png" alt="Visual Results" title="Visual Results" width="100%" style="max-width: 900px;">
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{motoda2024suctionprompt,
      title={SuctionPrompt: Visual-assisted Robotic Picking with a Suction Cup Using Vision-Language Models and Facile Hardware Design}, 
      author={Tomohiro Motoda and Takahide Kitamura and Ryo Hanai and Yukiyasu Domae},
      year={2024},
      eprint={2410.23640},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2410.23640}, 
  }</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>